{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d6e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pprint\n",
    "import google.generativeai as palm\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import openai\n",
    "import os\n",
    "from flask import Flask, render_template, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d368b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add your api key here\n",
    "palm.configure(api_key='AIzaSyDqErL4GIRikBNqN6n3qggnR4mNMw8w6p4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2b5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = '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'\n",
    "# Dakshta'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' \n",
    "# sara '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'\n",
    "# megha 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\n",
    "# me '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' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2faa0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are working with Generate Text model only\n",
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c1dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to call bard api and get prompt response\n",
    "def palmresponse(prompt):\n",
    "    completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_output_tokens=2000)\n",
    "\n",
    "    return completion.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4147e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_outcome_data(message):\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "    engine='text-davinci-003',#\"text-embedding-ada-002\",  \n",
    "    prompt=message,\n",
    "    max_tokens=2000,\n",
    "    n=1,\n",
    "    stop=None)\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8494ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert the string output to pandas dataframe\n",
    "def debtequitydf(bard):\n",
    "    import sys\n",
    "    if sys.version_info[0] < 3: \n",
    "        from StringIO import StringIO\n",
    "    else:\n",
    "        from io import StringIO\n",
    "\n",
    "    TESTDATA = StringIO(bard)\n",
    "    df = pd.read_csv(TESTDATA, sep=\"|\")\n",
    "    return df.iloc[1:,1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdcb29bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to generate prompt for different companies\n",
    "def bardoutcome_data(company,type1):\n",
    "    #add your prompt here\n",
    "    prompt =\"fetch the data for fields- total debt, total equity, total debt on total equity, diluted eps, total revenue,\\\n",
    "    net income, EBITDA,Long Term Investment,Interest Expense,Return on Equity,Cash \\\n",
    "    and Cash Equivalents ,Quick Ratio,Current Ratio  for \"+company + \"from FY 2020 to 2022 and  \\\n",
    "    triple checked this data and it is all consistent across\\\n",
    "    Google Finance, Yahoo Finance, and Investing.com.\"\n",
    "    if type1=='Bard':\n",
    "        response=palmresponse(prompt)\n",
    "    elif type1=='ChatGpt':\n",
    "        #print(prompt)\n",
    "        response=gpt_outcome_data(prompt)\n",
    "        #print(response)\n",
    "    return response\n",
    "# Also if \"+company +\" is a good company to invest in 2023 and \\     how much % return someone can get on 1000 usd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33293028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate prompt for different companies\n",
    "def bardoutcome_investment(company, data,type1):\n",
    "    #add your prompt here\n",
    "    prompt =\"Is \"+company+\" a good company to invest in 2023 and how much % return someone can expect to get on $1000. \\\n",
    "    Use this data to analyze - Total Debt,Total Equity,Total Debt on Total Equity,Diluted EPS,Total Revenue,Net Income,EBITDA,\\\n",
    "    Long Term Investment,Interest Expense,Return on Equity,Cash and Cash Equivalents ,Quick Ratio,Current Ratio  \"+ data \n",
    "    \n",
    "    if type1=='Bard':\n",
    "        response=palmresponse(prompt)\n",
    "    elif type1=='ChatGpt':\n",
    "        response=gpt_outcome_data(prompt)\n",
    "    return response\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac80956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate prompt for different companies\n",
    "def bardoutcome_investment1(company,data,type1):\n",
    "    #add your prompt here\n",
    "    prompt =\"Is \"+company+\" a good company to invest in 2023 and how much % return someone can expect to get on $1000. \\\n",
    "    Use this data to analyze - Total Debt,Total Equity,Total Debt on Total Equity,Diluted EPS,Total Revenue,Net Income,EBITDA,\\\n",
    "    Long Term Investment,Interest Expense,Return on Equity,Cash and Cash Equivalents ,Quick Ratio,Current Ratio  \"+ data[0] + data[1] + data[2] \n",
    "    \n",
    "    if type1=='Bard':\n",
    "        response=palmresponse(prompt)\n",
    "    elif type1=='ChatGpt':\n",
    "        response=gpt_outcome_data(prompt)\n",
    "    return response\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "343eeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(t1):\n",
    "    prompt =\"perform sentiment analysis of this text\"+ str(t1) +\"in single keyword as positive, negative or neutral\"\n",
    "    response = str(palmresponse(prompt))    \n",
    "    if response == 'positive':\n",
    "        return \"Received \" + response +\" sentiment analysis from Bard\",'Yes'\n",
    "    elif response == 'negative':\n",
    "        return \"Received \" + response +\" sentiment analysis from Bard\",'No'\n",
    "    if response == 'neutral':\n",
    "        return \"Received \" + response +\" sentiment analysis from Bard\",'Maybe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d720da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stopwords and generate bag of words\n",
    "import nltk\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    # Create a set of stopwords.\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    # Split the string into a list of words.\n",
    "    #print(string)\n",
    "    words = str(string).split()\n",
    "    # Remove the stopwords from the list of words.\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    # Join the filtered words back into a string.\n",
    "    filtered_string = ' '.join(filtered_words)\n",
    "    # Return the filtered string.\n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f09e7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty dataframe to store result\n",
    "final_data=pd.DataFrame(columns=['Company_name','dates','bard_company_info','bard_recommendation', \"Investment_Y/N\",\"Sentiment_of_investment\",\"Latest_news\",\n",
    "                                 \"sentiment_of_latest_news\",\"past_news\",\"highest_match\",\"sentiment_of_match\"],index=range(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58a646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty dataframe to store result\n",
    "final_datagpt=pd.DataFrame(columns=['Company_name','dates','bard_company_info','bard_recommendation', \"Investment_Y/N\",\"Sentiment_of_investment\",\"Latest_news\",\n",
    "                                 \"sentiment_of_latest_news\",\"past_news\",\"highest_match\",\"sentiment_of_match\"],index=range(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94ccedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complete_process(company_name,dates,type1):\n",
    "    \n",
    "    bard_data=bardoutcome_data(company_name,type1)\n",
    "    #print(bard_data)\n",
    "    bard_outcome=bardoutcome_investment(company_name, bard_data,type1)\n",
    "    #print(bard_outcome)\n",
    "    \n",
    "    sentiment_bard, flag=sentiment_analysis(bard_outcome)\n",
    "    #print(sentiment_bard)\n",
    "    prompt =\"latest wall street journal news for \"+company_name +\" in ** format\"\n",
    "    t1=palmresponse(prompt)\n",
    "    #print(t1)\n",
    "    #print(\"This is the latest news only headline in wall street journal for \"+ company_name)\n",
    "    \n",
    "    t1=t1.split(\"**\")[2]\n",
    "    s1,flag1=sentiment_analysis(t1)\n",
    "    #print(s1)\n",
    "    \n",
    "    from io import StringIO\n",
    "    df = pd.read_csv(StringIO(palmresponse(\"pull \" + company_name +\" news from wall street journal only for these dates \" + \\\n",
    "                                           dates +  \" in tabular format\")), sep=\"|\")\n",
    "    df=df.iloc[1:,1:-1]\n",
    "    #print(df)\n",
    "    \n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2),max_features=50)\n",
    "\n",
    "    # Transform the texts into TF-IDF vectors.\n",
    "    hist_vector = vectorizer.fit_transform(df.iloc[:,1].apply(lambda x: remove_stopwords(x)))\n",
    "    #print(hist_vector)\n",
    "    #print(\"hist_vector\")\n",
    "    current_vector=vectorizer.transform(pd.Series(t1).apply(lambda x: remove_stopwords(x)))\n",
    "    #print(current_vector)\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    cos=cosine_similarity( hist_vector,current_vector)\n",
    "    index_highest=pd.DataFrame(cos).idxmax()[0]\n",
    "    #print(\"sentiment analysis\")\n",
    "    s2=sentiment_analysis(df.iloc[index_highest,2])\n",
    "    #print(index_highest)\n",
    "    #print(s2)\n",
    "    \n",
    "    return bard_data, bard_outcome, flag,sentiment_bard, t1,s1,df.iloc[:,1],df.iloc[index_highest,1],s2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c0960",
   "metadata": {},
   "source": [
    "List of company names and important dates associated to those companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44cd9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_companies=['Apple','Amazon','Tesla','Meta','Pfizer','Moderna','Netflix','LVMH','Royal caribbean cruises ltd',\n",
    "                'Zillow','Walt disney co','Comcast','AT&T','Google','Salesforce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2fd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=['August 15 2022, July 28 2023, October 30 2020, January 5 2023',\n",
    "       'March 29 2022,July 31 2023,November 2 ,2020, January 5 2023',\n",
    "          ' November 4 2021,April 4 2022,Friday October 30 2020,Tuesday January 3 2023',\n",
    "       '9/7/21,7/28/23,11/2/22,3/11/22',\n",
    "           'November 9 2020 - November 25 2020,November 2 2021 - November 5 2021,May 22 2023 - May 31 2023',\n",
    "          'June 18 2021 - July 28 2021,November 11 2021 - November 29 2021,January 10 2022 - January 27 2022',\n",
    "        'September 17 2021 - October 15 2021, April 8 2022 - May 6 2022,April 28 2023 - June 30 2023',\n",
    "       'October 16 2020 - November 13 2020,August 6 2021 - September 10 2021,Septmeber 09 2022 - November 04 2022',\n",
    "       'Feburary 14 2020 - March 13 2020,April 24 2022 - May 13 2022,September 30 2022 - October 24 2022',\n",
    "       'Feburary 21 2020 - March 20 2020,Janurary 29 2021 - Feb 12 2021,October 29 2021 - November 26 2021',\n",
    "       'October 30 2020 - November 30 2020,March 18 2022 - April 22 2022,December 30 2022 - Janurary 27 2023',\n",
    "       'Feburary 14 2020 - March 20 2020,September 3 2021 - October 1 2021,September 9 2022 - October 7 2022',\n",
    "       'March 6 2020 - April 3 2020, October 22 2021 - December 10 2021,August 12 2022 - September 30 2022',\n",
    "       'July 31 2020 - August 28 2020,Janurary 5 2021 - Feburary 5 2021,March 25 2022 - May 27 2022',\n",
    "       'November 12 2021 - December 3 2021,December 16 2021 - January 20 2023,Feburary 14 2020- March 13 2020'\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ed6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.iloc[:,0]=list_companies\n",
    "final_data.iloc[:,1]=dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6288934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>dates</th>\n",
       "      <th>bard_company_info</th>\n",
       "      <th>bard_recommendation</th>\n",
       "      <th>Investment_Y/N</th>\n",
       "      <th>Sentiment_of_investment</th>\n",
       "      <th>Latest_news</th>\n",
       "      <th>sentiment_of_latest_news</th>\n",
       "      <th>past_news</th>\n",
       "      <th>highest_match</th>\n",
       "      <th>sentiment_of_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>August 15 2022, July 28 2023, October 30 2020,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>March 29 2022,July 31 2023,November 2 ,2020, J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>November 4 2021,April 4 2022,Friday October 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta</td>\n",
       "      <td>9/7/21,7/28/23,11/2/22,3/11/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pfizer</td>\n",
       "      <td>November 9 2020 - November 25 2020,November 2 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Moderna</td>\n",
       "      <td>June 18 2021 - July 28 2021,November 11 2021 -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>September 17 2021 - October 15 2021, April 8 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LVMH</td>\n",
       "      <td>October 16 2020 - November 13 2020,August 6 20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Royal caribbean cruises ltd</td>\n",
       "      <td>Feburary 14 2020 - March 13 2020,April 24 2022...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zillow</td>\n",
       "      <td>Feburary 21 2020 - March 20 2020,Janurary 29 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walt disney co</td>\n",
       "      <td>October 30 2020 - November 30 2020,March 18 20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Comcast</td>\n",
       "      <td>Feburary 14 2020 - March 20 2020,September 3 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>March 6 2020 - April 3 2020, October 22 2021 -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Google</td>\n",
       "      <td>July 31 2020 - August 28 2020,Janurary 5 2021 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Salesforce</td>\n",
       "      <td>November 12 2021 - December 3 2021,December 16...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Company_name  \\\n",
       "0                         Apple   \n",
       "1                        Amazon   \n",
       "2                         Tesla   \n",
       "3                          Meta   \n",
       "4                        Pfizer   \n",
       "5                       Moderna   \n",
       "6                       Netflix   \n",
       "7                          LVMH   \n",
       "8   Royal caribbean cruises ltd   \n",
       "9                        Zillow   \n",
       "10               Walt disney co   \n",
       "11                      Comcast   \n",
       "12                         AT&T   \n",
       "13                       Google   \n",
       "14                   Salesforce   \n",
       "\n",
       "                                                dates bard_company_info  \\\n",
       "0   August 15 2022, July 28 2023, October 30 2020,...               NaN   \n",
       "1   March 29 2022,July 31 2023,November 2 ,2020, J...               NaN   \n",
       "2    November 4 2021,April 4 2022,Friday October 3...               NaN   \n",
       "3                      9/7/21,7/28/23,11/2/22,3/11/22               NaN   \n",
       "4   November 9 2020 - November 25 2020,November 2 ...               NaN   \n",
       "5   June 18 2021 - July 28 2021,November 11 2021 -...               NaN   \n",
       "6   September 17 2021 - October 15 2021, April 8 2...               NaN   \n",
       "7   October 16 2020 - November 13 2020,August 6 20...               NaN   \n",
       "8   Feburary 14 2020 - March 13 2020,April 24 2022...               NaN   \n",
       "9   Feburary 21 2020 - March 20 2020,Janurary 29 2...               NaN   \n",
       "10  October 30 2020 - November 30 2020,March 18 20...               NaN   \n",
       "11  Feburary 14 2020 - March 20 2020,September 3 2...               NaN   \n",
       "12  March 6 2020 - April 3 2020, October 22 2021 -...               NaN   \n",
       "13  July 31 2020 - August 28 2020,Janurary 5 2021 ...               NaN   \n",
       "14  November 12 2021 - December 3 2021,December 16...               NaN   \n",
       "\n",
       "   bard_recommendation Investment_Y/N Sentiment_of_investment Latest_news  \\\n",
       "0                  NaN            NaN                     NaN         NaN   \n",
       "1                  NaN            NaN                     NaN         NaN   \n",
       "2                  NaN            NaN                     NaN         NaN   \n",
       "3                  NaN            NaN                     NaN         NaN   \n",
       "4                  NaN            NaN                     NaN         NaN   \n",
       "5                  NaN            NaN                     NaN         NaN   \n",
       "6                  NaN            NaN                     NaN         NaN   \n",
       "7                  NaN            NaN                     NaN         NaN   \n",
       "8                  NaN            NaN                     NaN         NaN   \n",
       "9                  NaN            NaN                     NaN         NaN   \n",
       "10                 NaN            NaN                     NaN         NaN   \n",
       "11                 NaN            NaN                     NaN         NaN   \n",
       "12                 NaN            NaN                     NaN         NaN   \n",
       "13                 NaN            NaN                     NaN         NaN   \n",
       "14                 NaN            NaN                     NaN         NaN   \n",
       "\n",
       "   sentiment_of_latest_news past_news highest_match sentiment_of_match  \n",
       "0                       NaN       NaN           NaN                NaN  \n",
       "1                       NaN       NaN           NaN                NaN  \n",
       "2                       NaN       NaN           NaN                NaN  \n",
       "3                       NaN       NaN           NaN                NaN  \n",
       "4                       NaN       NaN           NaN                NaN  \n",
       "5                       NaN       NaN           NaN                NaN  \n",
       "6                       NaN       NaN           NaN                NaN  \n",
       "7                       NaN       NaN           NaN                NaN  \n",
       "8                       NaN       NaN           NaN                NaN  \n",
       "9                       NaN       NaN           NaN                NaN  \n",
       "10                      NaN       NaN           NaN                NaN  \n",
       "11                      NaN       NaN           NaN                NaN  \n",
       "12                      NaN       NaN           NaN                NaN  \n",
       "13                      NaN       NaN           NaN                NaN  \n",
       "14                      NaN       NaN           NaN                NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4a46563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def final_response(company_name, date, type1):\n",
    "    return complete_process(company_name,date,type1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312dd18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
